{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formal-palmer",
   "metadata": {
    "id": "formal-palmer"
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indian-calendar",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7190,
     "status": "ok",
     "timestamp": 1620316010186,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "indian-calendar",
    "outputId": "938cdc53-533a-491a-9da0-f93a4d3a6ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D ,MaxPooling2D, MaxPool2D , Flatten , Dropout \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "image_path = \"dataset_train/dataset/\"\n",
    "#!unzip dataset_train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-gentleman",
   "metadata": {
    "id": "agricultural-gentleman"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "irish-straight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12715,
     "status": "ok",
     "timestamp": 1620316016821,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "irish-straight",
    "outputId": "95291602-a45f-4dfc-8550-1884cbd3b712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadDataSet(path):\n",
    "    def loadImages(path):\n",
    "        # literalmente dar load das imagens todas para estes arrays\n",
    "        # Listas por compreencao for life <3\n",
    "        real = [image.load_img(image_path+\"real/\"+file,target_size = (28,28), color_mode='grayscale') for file in os.listdir(image_path+\"real\")]\n",
    "        fake = [image.load_img(image_path+\"fake/\"+file,target_size = (28,28), color_mode='grayscale') for file in os.listdir(image_path+\"/fake\")]\n",
    "        return real,fake\n",
    "\n",
    "    def imagesToArray(imgs):\n",
    "        return np.array([image.img_to_array(img)[:,:,0] for img in imgs])\n",
    "    \n",
    "    real,fake = loadImages(path)\n",
    "    real_array = imagesToArray(real)\n",
    "    fake_array = imagesToArray(fake)\n",
    "    return real_array,fake_array\n",
    "  \n",
    "real,fake = loadDataSet(image_path)\n",
    "len(real),len(fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-revolution",
   "metadata": {
    "id": "union-revolution"
   },
   "source": [
    "# Train Val Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modified-tracy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10932,
     "status": "ok",
     "timestamp": 1620316016824,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "modified-tracy",
    "outputId": "d2296978-2802-44c8-89f1-04d1df64ebbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> 24000 [60.0%] \n",
      "Val   -> 8000 [20.0%] \n",
      "Test  -> 8000 [20.0%] \n"
     ]
    }
   ],
   "source": [
    "X = np.append(real,fake,axis=0)\n",
    "y = np.append(np.ones((20000,1)),np.zeros((20000,1)))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=13)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size=0.5, random_state=13)\n",
    "print(\"Train -> {} [{}%] \".format(len(y_train),len(y_train)/40000*100))\n",
    "print(\"Val   -> {} [{}%] \".format(len(y_val),len(y_val)/40000*100))\n",
    "print(\"Test  -> {} [{}%] \".format(len(y_test),len(y_test)/40000*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-medicaid",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1620316160566,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "clean-medicaid",
    "outputId": "7340b38b-cea5-427f-8cdb-48d4bace2edc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, frequency_train = np.unique(y_train, return_counts = True)\n",
    "_, frequency_val = np.unique(y_val, return_counts = True)\n",
    "_, frequency_test = np.unique(y_test, return_counts = True)\n",
    "\n",
    "plt.bar([\"Fake\",\"Real\"], frequency_train,label ='Train',color=\"#C97064\")\n",
    "plt.bar([\"Fake\",\"Real\"], frequency_val,label ='Validation',color=\"#BCA371\",bottom=frequency_train)\n",
    "plt.bar([\"Fake\",\"Real\"], frequency_test,label ='Test',color=\"#32965D\",bottom=np.add(frequency_train, frequency_test))\n",
    "plt.legend()\n",
    "plt.title(\"Train Val Test - Distribution\")\n",
    "plt.show()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-plenty",
   "metadata": {
    "id": "bright-plenty"
   },
   "source": [
    "# Models\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-exception",
   "metadata": {
    "id": "digital-exception"
   },
   "source": [
    "## Xception\n",
    "https://keras.io/api/applications/xception/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deluxe-swedish",
   "metadata": {
    "id": "deluxe-swedish",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6c05d43df2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_xception =tf.keras.applications.Xception(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"imagenet\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tferr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\xception.py\u001b[0m in \u001b[0;36mXception\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'imagenet'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minclude_top\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n\u001b[0m\u001b[0;32m    123\u001b[0m                      ' as true, `classes` should be 1000')\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "model_xception =tf.keras.applications.Xception(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(28,28,1),\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U0c74cjT12Du",
   "metadata": {
    "id": "U0c74cjT12Du"
   },
   "source": [
    "# Modelo OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "significant-brief",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5766,
     "status": "ok",
     "timestamp": 1620170331103,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "significant-brief",
    "outputId": "6cd32bda-6e16-4b1e-fb32-791477fa2a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1982592   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,076,257\n",
      "Trainable params: 2,076,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "equal-purchase",
   "metadata": {
    "id": "equal-purchase"
   },
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "'''model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=[Accuracy(), Precision(), Recall(), AUC()]\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "piano-supplier",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455329,
     "status": "ok",
     "timestamp": 1620170854131,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "piano-supplier",
    "outputId": "3c541907-8c43-4829-f83e-770527590dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 151s 199ms/step - loss: 0.6202 - accuracy: 0.4975 - precision_7: 0.4975 - recall_7: 1.0000 - auc_7: 0.5000 - val_loss: 0.2768 - val_accuracy: 0.5015 - val_precision_7: 0.5015 - val_recall_7: 1.0000 - val_auc_7: 0.5000 preci\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 1 ,batch_size=32, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "accessory-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_test_save\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_test_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.6931 - accuracy: 0.4985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931461095809937, 0.4984999895095825]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('C:\\\\Users\\\\tferr\\\\Desktop\\\\ACA\\\\Projeto\\\\Project_Assignment_To_Students\\\\To_Students\\\\AML-Project\\\\Models\\\\Testes\\\\relu_relu_0.5\\\\model_drop0.5_epochs100_act-relu_relu')\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V5Owxw5jtNgH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1620172822528,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "V5Owxw5jtNgH",
    "outputId": "e3e9480c-43a9-497d-ee31-b63f65fb9045"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l4bN2d7EtOFO",
   "metadata": {
    "id": "l4bN2d7EtOFO"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o4KnO3TWtOI_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1620170901598,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "o4KnO3TWtOI_",
    "outputId": "ebd1d746-e87d-403c-d94b-0a1faf797507"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names = ['Fake (Class 0)','Real (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4pd3tNSOt01m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1620170992763,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "4pd3tNSOt01m",
    "outputId": "4eef4b70-b703-4dd5-822b-638b52759cd2"
   },
   "outputs": [],
   "source": [
    "!unzip dataset_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EGkRo163th2u",
   "metadata": {
    "id": "EGkRo163th2u"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_path = \"dataset_test/dataset_test\"\n",
    "\n",
    "def loadTestSet(path):\n",
    "    def loadImages(path):\n",
    "        # literalmente dar load das imagens todas para estes arrays\n",
    "        # Listas por compreencao for life <3\n",
    "        images = [image.load_img(image_path+\"/images/\"+file,target_size = (28,28), color_mode='grayscale') for file in sorted(os.listdir(image_path+\"/images\"))]\n",
    "        return images\n",
    "\n",
    "    def imagesToArray(imgs):\n",
    "        return np.array([image.img_to_array(img)[:,:,0] for img in imgs])\n",
    "    \n",
    "    images = loadImages(path)\n",
    "    images_array = imagesToArray(images)\n",
    "    return images_array\n",
    "  \n",
    "test_set = loadTestSet(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SqnYqJfKtvRw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1620172219540,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "SqnYqJfKtvRw",
    "outputId": "336df5a0-3014-4d5f-e0e2-2ce724b86918"
   },
   "outputs": [],
   "source": [
    "test_set = test_set.reshape(-1, 28, 28, 1)\n",
    "predictions = model.predict_classes(test_set)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o4KxCu_ztvT8",
   "metadata": {
    "id": "o4KxCu_ztvT8"
   },
   "outputs": [],
   "source": [
    "ids = [img.split(\".\")[0] for img in sorted(os.listdir(\"dataset_test/dataset_test/images\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pNqAWv8utvXL",
   "metadata": {
    "id": "pNqAWv8utvXL"
   },
   "outputs": [],
   "source": [
    "submition = pd.DataFrame((np.array([ids,predictions]).T),columns= [\"Id\",\"Category\"])\n",
    "submition = submition.astype(int).sort_values(\"Id\")\n",
    "submition.to_csv(\"Submition.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PJT04oL8tvab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1620171114160,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "PJT04oL8tvab",
    "outputId": "bf6ac6f5-ab47-418d-dedc-ec2767b4c32a"
   },
   "outputs": [],
   "source": [
    "model.save('second_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-sculpture",
   "metadata": {
    "id": "graduate-sculpture"
   },
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jY7Pu9kQTTqd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1620316053427,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "jY7Pu9kQTTqd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import RandomFourierFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ySnxVTT6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1720,
     "status": "ok",
     "timestamp": 1620316407286,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "cd4ySnxVTT6f",
    "outputId": "303a3f79-70b0-4ab1-80c4-b56683691f86"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "RandomFourierFeatures(\n",
    "      output_dim=64,\n",
    "      trainable=\"True\",\n",
    "      kernel_initializer='gaussian'),\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax')),\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "model.compile(optimizer = opt , loss = \"hinge\" , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRRtB8XqTUAC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "executionInfo": {
     "elapsed": 76040,
     "status": "error",
     "timestamp": 1620316483993,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "SRRtB8XqTUAC",
    "outputId": "4a1ca688-a45c-4dea-f5bb-9491bfed6495"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 100 , validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0vE2QEBV2FXG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1620251066115,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "0vE2QEBV2FXG",
    "outputId": "81c7c6a7-e3d0-4b4d-cec0-42170e869477"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(val_loss))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_kis5Scs2AR9",
   "metadata": {
    "id": "_kis5Scs2AR9"
   },
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opUxAeGdZ2To",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "ok",
     "timestamp": 1620258375992,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "opUxAeGdZ2To",
    "outputId": "90100b04-5909-4d14-a650-fdbb808a08a1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax')),\n",
    "\n",
    "opt = Adam(lr=0.01)\n",
    "model.compile(optimizer = \"adam\" , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKLFh8Rs1-mG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "error",
     "timestamp": 1620258393981,
     "user": {
      "displayName": "Miguel Marques",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgxI4tbibdSB-1GNL3pUyRpvdf4mjk4ad6sMxNQeg=s64",
      "userId": "04941611119444813601"
     },
     "user_tz": -60
    },
    "id": "jKLFh8Rs1-mG",
    "outputId": "bb8f7e7d-c770-4cb3-8342-43da81ae406f"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 100 , validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-memorabilia",
   "metadata": {},
   "source": [
    "## scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5ubcB141-o4",
   "metadata": {
    "id": "j5ubcB141-o4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import skimage\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AgtBWeLq1-sC",
   "metadata": {
    "id": "AgtBWeLq1-sC"
   },
   "outputs": [],
   "source": [
    "# create an instance of each transformer\n",
    "hogify = HogTransformer(\n",
    "    pixels_per_cell=(14, 14), \n",
    "    cells_per_block=(2,2), \n",
    "    orientations=9, \n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "scalify = StandardScaler()\n",
    " \n",
    "# call fit_transform on each transform converting X_train step by step\n",
    "X_train_hog = hogify.fit_transform(X_train)\n",
    "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
    " \n",
    "print(X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LGnggjKA1-ud",
   "metadata": {
    "id": "LGnggjKA1-ud"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
